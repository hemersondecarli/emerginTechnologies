{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c1c388a-9f8b-48ad-aa91-0345fe585f94",
   "metadata": {},
   "source": [
    "# Third-order Letter Approximation Model\n",
    "- Creating a third-order letter approximation model from five English texts sourced from Project Gutenberg. texts will be processed by:\n",
    "- Removing unnecessary content (preamble, postamble).\n",
    "- Retaining only ASCII letters, full stops, and spaces.\n",
    "- Converting all letters to uppercase.\n",
    "\n",
    "Count the occurrences of each trigram (a sequence of three characters) to build a model of the English language based on these texts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e1b8d5-f530-4a02-a266-cb053a9fa736",
   "metadata": {},
   "source": [
    "# .txt files saved on local directory / using py. to read them.\n",
    "\n",
    "# ref: https://realpython.com/read-write-files-python/\n",
    "# https://www.dataquest.io/blog/read-file-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd73d5a5-0c3b-4127-a202-86ea1dd64c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loaded Texts (First 500 Characters of Each Text):\n",
      "Text 1:\n",
      "The Project Gutenberg eBook of My betrothed and other poems\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this\n",
      "----------------------------------------\n",
      "Text 2:\n",
      "The Project Gutenberg eBook of The chronicles of Enguerrand de Monstrelet\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n",
      "bef\n",
      "----------------------------------------\n",
      "Text 3:\n",
      "The Project Gutenberg eBook of Frank Hardy's choice\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this eBook.\n",
      "\n",
      "----------------------------------------\n",
      "Text 4:\n",
      "The Project Gutenberg eBook of Bessie at school\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this eBook.\n",
      "\n",
      "Tit\n",
      "----------------------------------------\n",
      "Text 5:\n",
      "The Project Gutenberg eBook of A voyage of discovery\n",
      "    \n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this ebook or online\n",
      "at www.gutenberg.org. If you are not located in the United States,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this eBook.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# List of file paths for the texts\n",
    "import re\n",
    "\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\hemer\\emerginTechnologies\\Text\\betrothed.txt\",\n",
    "    r\"C:\\Users\\hemer\\emerginTechnologies\\Text\\chronicles.txt\",\n",
    "    r\"C:\\Users\\hemer\\emerginTechnologies\\Text\\Frank.txt\",\n",
    "    r\"C:\\Users\\hemer\\emerginTechnologies\\Text\\school.txt\",\n",
    "    r\"C:\\Users\\hemer\\emerginTechnologies\\Text\\voyage.txt\"\n",
    "]\n",
    "\n",
    "# Function to load texts\n",
    "def load_texts(file_paths):\n",
    "    texts = []\n",
    "    for path in file_paths:\n",
    "        with open(path, 'r', encoding='utf-8') as file:\n",
    "            texts.append(file.read())\n",
    "    return texts\n",
    "\n",
    "# Load all texts and display the first 500 characters of each for verification\n",
    "texts = load_texts(file_paths)\n",
    "print(\"Step 1: Loaded Texts (First 500 Characters of Each Text):\")\n",
    "for i, text in enumerate(texts):\n",
    "    print(f\"Text {i+1}:\\n{text[:500]}\\n{'-'*40}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6fd3a7-fea8-4047-bac3-75d114d09ce0",
   "metadata": {},
   "source": [
    "# Remove preamble and postamble, Removes all characters except ASCII letters, spaces, and full stops andConverts all letters to uppercase.\n",
    "# Ref: https://datagy.io/python-read-text-file/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a278fc8f-93a8-4e13-b8d2-7e8100306d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Preprocessed Texts (First 500 Characters of Each Text):\n",
      "Processed Text 1:\n",
      "THE PROJECT GUTENBERG EBOOK OF MY BETROTHED AND OTHER POEMS    THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES ANDMOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONSWHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMSOF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINEAT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATESYOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATEDBEFORE USING THIS EBOOK.TITL\n",
      "----------------------------------------\n",
      "Processed Text 2:\n",
      "THE PROJECT GUTENBERG EBOOK OF THE CHRONICLES OF ENGUERRAND DE MONSTRELET    THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES ANDMOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONSWHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMSOF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINEAT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATESYOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATEDBEFORE USING T\n",
      "----------------------------------------\n",
      "Processed Text 3:\n",
      "THE PROJECT GUTENBERG EBOOK OF FRANK HARDYS CHOICE    THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES ANDMOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONSWHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMSOF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINEAT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATESYOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATEDBEFORE USING THIS EBOOK.TITLE FRANK H\n",
      "----------------------------------------\n",
      "Processed Text 4:\n",
      "THE PROJECT GUTENBERG EBOOK OF BESSIE AT SCHOOL    THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES ANDMOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONSWHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMSOF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINEAT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATESYOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATEDBEFORE USING THIS EBOOK.TITLE BESSIE AT \n",
      "----------------------------------------\n",
      "Processed Text 5:\n",
      "THE PROJECT GUTENBERG EBOOK OF A VOYAGE OF DISCOVERY    THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES ANDMOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONSWHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMSOF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINEAT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATESYOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATEDBEFORE USING THIS EBOOK.TITLE A VOY\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Function to preprocess each text\n",
    "def preprocess_text(text):\n",
    "    # Remove preamble and postamble\n",
    "    start_marker = \"START OF THIS PROJECT GUTENBERG EBOOK\"\n",
    "    end_marker = \"END OF THIS PROJECT GUTENBERG EBOOK\"\n",
    "    \n",
    "    start_pos = text.find(start_marker)\n",
    "    end_pos = text.find(end_marker)\n",
    "    \n",
    "    # Slice text to keep only the main content\n",
    "    if start_pos != -1:\n",
    "        text = text[start_pos + len(start_marker):]\n",
    "    if end_pos != -1:\n",
    "        text = text[:end_pos]\n",
    "    \n",
    "    # Remove unwanted characters, keep only ASCII letters, full stops, and spaces\n",
    "    text = re.sub(r'[^A-Za-z. ]', '', text)\n",
    "    text = text.upper()  # Convert to uppercase\n",
    "    return text\n",
    "\n",
    "# Preprocess each text and display the first 500 characters after preprocessing\n",
    "processed_texts = [preprocess_text(text) for text in texts]\n",
    "print(\"\\nStep 2: Preprocessed Texts (First 500 Characters of Each Text):\")\n",
    "for i, text in enumerate(processed_texts):\n",
    "    print(f\"Processed Text {i+1}:\\n{text[:500]}\\n{'-'*40}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd97e86-f0bc-4d11-a0e9-780a9639a589",
   "metadata": {},
   "source": [
    "# Creates a function to iterate through each preprocessed text and extract trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "abeb7752-77c6-4e2b-8614-008629d1c5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Trigram Model Sample (10 Trigrams with Counts):\n",
      "'THE': 22719\n",
      "'HE ': 19788\n",
      "'E P': 2035\n",
      "' PR': 2578\n",
      "'PRO': 1583\n",
      "'ROJ': 445\n",
      "'OJE': 445\n",
      "'JEC': 597\n",
      "'ECT': 1577\n",
      "'CT ': 808\n"
     ]
    }
   ],
   "source": [
    "# Function to generate trigram model\n",
    "def generate_trigram_model(texts):\n",
    "    trigram_counts = {}  # Dictionary to store trigram counts\n",
    "\n",
    "    for text in texts:\n",
    "        for i in range(len(text) - 2):  # Loop through each character up to the third-to-last\n",
    "            trigram = text[i:i + 3]  # Extract a trigram of three characters\n",
    "            if trigram in trigram_counts:\n",
    "                trigram_counts[trigram] += 1  # Increment count if trigram exists\n",
    "            else:\n",
    "                trigram_counts[trigram] = 1  # Initialize count if trigram is new\n",
    "    \n",
    "    return trigram_counts\n",
    "\n",
    "# Generate the trigram model and display a sample of 10 items\n",
    "trigram_model = generate_trigram_model(processed_texts)\n",
    "print(\"\\nStep 3: Trigram Model Sample (10 Trigrams with Counts):\")\n",
    "sample_trigrams = list(trigram_model.items())[:10]\n",
    "for trigram, count in sample_trigrams:\n",
    "    print(f\"'{trigram}': {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565587df-f903-4d24-bbdc-1b0bfd73e57d",
   "metadata": {},
   "source": [
    "# Creates a function to display the most common tiagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bd4a4e13-9c18-4b98-b5c1-6438113beeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Top 10 Most Common Trigrams\n",
      "' TH': 25434\n",
      "'THE': 22719\n",
      "'HE ': 19788\n",
      "'   ': 17800\n",
      "'AND': 10688\n",
      "'ND ': 10315\n",
      "' AN': 10238\n",
      "'ED ': 9757\n",
      "' TO': 9718\n",
      "' OF': 9412\n"
     ]
    }
   ],
   "source": [
    "# Display top N trigrams (e.g., top 10)\n",
    "def display_top_trigrams(trigram_model, top_n=10):\n",
    "    # Sort trigrams by count in descending order\n",
    "    sorted_trigrams = sorted(trigram_model.items(), key=lambda item: item[1], reverse=True)\n",
    "    # Display the top N trigrams\n",
    "    print(f\"\\nStep 4: Top {top_n} Most Common Trigrams\")\n",
    "    for trigram, count in sorted_trigrams[:top_n]:\n",
    "        print(f\"'{trigram}': {count}\")\n",
    "\n",
    "# Display the 10 most common trigrams\n",
    "display_top_trigrams(trigram_model, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d22321-57d8-4449-86d3-2236378e8660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
